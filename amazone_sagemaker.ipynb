{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ffbbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess=sagemaker.Session()\n",
    "\n",
    "\n",
    "# sagemaker session bucket -> used for uploading data model and log.\n",
    "#sagemaker will automatically create this bucket if it not exist.\n",
    "\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket=sess.default_bucket()\n",
    "\n",
    "\n",
    "### Role management \n",
    "try:\n",
    "    pass\n",
    "except ValueError:\n",
    "    iam=boto3.client(\"iam\")\n",
    "    role=iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "\n",
    "session=sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "\n",
    "print(f\"sagemaker roal Arn :{role}\")\n",
    "print(f\"sagemaker session regain:{sess.boto_region_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34befd7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sagemaker'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msagemaker\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhuggingface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceModel\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Hub model configuration <http://huggingface.co/models>\u001b[39;00m\n\u001b[32m      3\u001b[39m hub={\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mHF_MODEL_ID\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mdistilbert-base-uncased-distilled-squad\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;66;03m#model id from hf.co/models\u001b[39;00m\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mHF_TASK\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mquestion-answering\u001b[39m\u001b[33m'\u001b[39m                          \u001b[38;5;66;03m# nLP task you want to use for predictions\u001b[39;00m\n\u001b[32m      6\u001b[39m }\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sagemaker'"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "# Hub model configuration <http://huggingface.co/models>\n",
    "hub={\n",
    "    'HF_MODEL_ID':'distilbert-base-uncased-distilled-squad',#model id from hf.co/models\n",
    "    'HF_TASK':'question-answering'                          # nLP task you want to use for predictions\n",
    "}\n",
    "\n",
    "# create Hugingface Model class\n",
    "huggingface_model=HuggingFaceModel(\n",
    "    env=hub,\n",
    "    role=role\n",
    "    transformers_version=\"4.26\",\n",
    "    pytorch_version=\"1.13\",\n",
    "    py_version='py39',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daf7083",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b6d9858",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'huggingface_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# deploy model to sagemaker inference\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m predictor=\u001b[43mhuggingface_model\u001b[49m.deploy(\n\u001b[32m      3\u001b[39m     initial_instance_count=\u001b[32m1\u001b[39m,\n\u001b[32m      4\u001b[39m     instance_type=\u001b[33m\"\u001b[39m\u001b[33mml.m5.xlarge\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'huggingface_model' is not defined"
     ]
    }
   ],
   "source": [
    "# deploy model to sagemaker inference\n",
    "predictor=huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\"\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d933336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example request: you always need to define \"inputs\"\n",
    "data={\n",
    "    \"inputs\":{\n",
    "        \"question\":\"what is used for inference?\",\n",
    "        \"context\":\"My Name is Philipp and i live in Nuremberg.This model is used with sagemaker for inferance.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "#request\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1549fa",
   "metadata": {},
   "source": [
    "Compared to deploy regulare huggingface model we first need to retrive the container uri and provide it to our Huggingface model\n",
    "model class with image url pointing to image to retirve the new hugging face LLM Deep learning container in amazon sagemaker\n",
    "we can use the get_huggingface LLM imageurl method provided bt sagemaker SDK this method allows us to retrive the url for the desired huggingface LLM DLS based on the specified backend session region and version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469df60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "# retrive the llm image uri\n",
    "llm_image=get_huggingface_llm_image_uri(\n",
    "    \"huggingface\",\n",
    "    version=\"0.8.2\"\n",
    ")\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri:{llm_image}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92197687",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
